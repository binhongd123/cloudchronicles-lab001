- **Primary Region**: europe-west1
- **Backup Location**: europe-west4
- **RTO (Recovery Time Objective)**: Aim for < 60 minutes for Dataflow pipeline re-activation.
- **RPO (Recovery Point Objective)**: Aim for < 5 minutes for data ingestion (critical to not lose any messages).

---

### **STAR-Based Disaster Recovery Plan: Data Pipeline Resilience**

#### **S - Situation:**
Our critical data processing pipeline, including Pub/Sub ingestion, Dataflow processing, BigQuery storage, and Cloud Storage archiving, is primarily deployed in the `europe-west1` region. A regional outage in `europe-west1` would halt data ingestion and real-time analytics, severely impacting business operations and leading to potential data loss.

#### **T - Task:**
To implement a robust disaster recovery plan that ensures continuous data ingestion and raw data archiving, along with the ability to resume core data processing, by failing over to `europe-west4` in the event of an `europe-west1` regional outage. We must achieve defined RTO and RPO targets for data availability.

#### **A - Action:**

**1. Pre-Outage Preparation (Continuous Readiness):**

* **Pub/Sub Messaging:**
    * Utilize **global Pub/Sub topics** (not regional) for all data ingestion. This ensures the topic itself is resilient to a single region failure.
    * For critical subscriptions that must continue processing, configure **cross-region push subscriptions** to Cloud Functions or Cloud Run services deployed in both `europe-west1` and `europe-west4`. Alternatively, set up pull subscriptions from consumers in both regions.
    * Enable **message retention** on topics for sufficient duration (e.g., 7 days) to allow for re-processing during recovery.
    * **GCP Tool:** Pub/Sub (Global Topics, Push/Pull Subscriptions), Cloud Functions/Cloud Run
* **Cloud Storage for Raw Data Archiving:**
    * Store all raw ingested data in a **Multi-Region Cloud Storage bucket** (e.g., `EU` multi-region). This provides automatic replication and access from either `europe-west1` or `europe-west4`.
    * **GCP Tool:** Cloud Storage (Multi-Region Buckets)
* **BigQuery Data Storage:**
    * For intermediate or final BigQuery datasets, consider **BigQuery multi-region datasets** (e.g., `EU` multi-region) for high availability and redundancy within the EU. Alternatively, implement cross-region dataset copying/replication for critical tables if granular control is needed.
    * **GCP Tool:** BigQuery (Multi-Region Datasets or Dataset Copies)
* **Dataflow Pipeline Templates:**
    * Pre-prepare and test **Dataflow job templates** that can be launched in either `europe-west1` or `europe-west4`. Ensure these templates are configurable to point to the appropriate regional resources (e.g., BigQuery datasets, Cloud Storage buckets).
    * **GCP Tool:** Dataflow (Flex Templates/Classic Templates)
* **Infrastructure as Code (IaC):**
    * Manage all pipeline infrastructure (Pub/Sub topics/subscriptions, BigQuery datasets, Dataflow job definitions, storage buckets) using **IaC (e.g., Terraform)**. This enables rapid and consistent deployment of pipeline components in the secondary region.
    * **GCP Tool:** Terraform (or Cloud Deployment Manager)

**2. Outage Detection & Notification:**

* **Failover Trigger:**
    * **Automated Monitoring:** **Cloud Monitoring** detects critical failures within the `europe-west1` region, such as sustained Dataflow job failures, Pub/Sub message backlog increases, or unresponsiveness of services.
    * **Alerting:** These monitoring alerts trigger notifications to designated **Pub/Sub alert topics**.
    * **Notification:** Subscribers to the Pub/Sub alert topic (e.g., PagerDuty for critical alerts, Cloud Functions for automated responses) inform the operations team and potentially trigger automated failover scripts.
    * **GCP Tool:** Cloud Monitoring, Pub/Sub

**3. Failover Process (Action during Outage):**

* **Continuous Data Ingestion (Automatic):**
    * Because Pub/Sub topics are global, inbound messages continue to be accepted even if `europe-west1` is down.
    * **Cross-region Pub/Sub push subscriptions** (or pull consumers) running in `europe-west4` immediately begin processing messages from the global topics. This ensures **RPO < 5 minutes** for data ingestion, as messages are not lost and can be processed from the healthy region.
    * Data ingested by these `europe-west4` consumers is immediately written to the **Multi-Region Cloud Storage bucket**, ensuring raw data archiving continues.
* **Dataflow Pipeline Activation:**
    * The operations team (or an automated script triggered by Pub/Sub alerts) launches a **new Dataflow job** from the pre-prepared template in the **`europe-west4` region**.
    * This new Dataflow job reads from the relevant Pub/Sub subscription and processes data, writing output to the **Multi-Region BigQuery dataset** (if applicable) or the `europe-west4` specific BigQuery dataset.
    * **GCP Tool:** Dataflow (Job Launching), Pub/Sub (Subscription processing), BigQuery (Dataset Access)

**4. Recovery & Failback (Post-Outage Cleanup):**

* **`europe-west1` Restoration Assessment:**
    * Once Google Cloud confirms the stability and restoration of `europe-west1`, assess the region's health.
* **Data Consistency Check:**
    * Verify the consistency of data written to BigQuery and Cloud Storage during the failover period.
* **Prepare `europe-west1` Pipeline:**
    * Once `europe-west1` is stable, re-launch the primary Dataflow pipeline in `europe-west1`.
    * Ensure any Pub/Sub subscriptions in `europe-west1` are reactivated or re-pointed if necessary.
* **Phased Traffic Shift (if applicable):**
    * If any external systems were configured to explicitly send data to `europe-west4` during the outage, slowly re-point them back to `europe-west1`. For Pub/Sub, no change is usually needed as topics are global.
* **Resource Decommissioning:**
    * Once the `europe-west1` pipeline is fully operational and verified, terminate the Dataflow job running in `europe-west4`. Scale down or remove any temporary `europe-west4` compute resources used for ingestion.
* **Post-Mortem Analysis:** Conduct a thorough review of the incident, failover, and failback to identify lessons learned and improve the DR plan.

#### **Expected Result:**

Upon successful execution, we expect:
* **Continuous Data Ingestion:** Near-zero interruption to incoming data streams, with messages processed and raw data archived.
* **Minimal Data Loss (RPO < 5 mins):** Due to global Pub/Sub topics and multi-region storage, data is preserved even during a regional outage.
* **Resumed Processing (RTO < 60 mins):** The core Dataflow processing pipeline will be re-activated in the secondary region within the target RTO.
* **Business Continuity:** Analytics dashboards fed by the pipeline will eventually recover, and no critical raw data will be lost.
* **Improved Resilience:** A validated and robust DR plan for our critical data pipeline.
